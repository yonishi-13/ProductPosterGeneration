# üñºÔ∏è Product Poster Generator

This repository contains a client-server web application for generating brand-specific posters using generative AI and basic layout logic. The system is designed with a modular architecture to enable interpretable and controllable image synthesis tailored for real-world marketing applications.

---

## üîß Key Updates

### üñ•Ô∏è Frontend (React.js)
A user-friendly web interface enables users to:
- Upload a **brand logo image**
- Upload a **background image**
- Enter **brand-related text**
- Specify **output image dimensions** (e.g., `512x512`)

Upon submission, all inputs are transmitted to the backend using an HTTP `POST` request in `multipart/form-data` format.

---

### üß† Backend (FastAPI + Python)
The backend is responsible for:
- Image preprocessing and layout logic
- Rendering brand assets and text
- Image generation using a modular machine learning pipeline

**Note:**  
No external layout generation framework (e.g., PlanNet, LayoutTransformer) is used at this stage.  
All layout-related decisions (e.g., positioning of logo and text) are handled through **direct logic coded in [`main.py`](./backend/main.py)**.

---

## üé® Prompt-Based Diffusion Approach (Previous Version)

This system originally used a **prompt-driven Stable Diffusion pipeline** with the Hugging Face `diffusers` library:

#### üîπ Prompt Engineering
User text was converted into descriptive prompts, e.g.:
> "A modern product poster featuring the logo of BrandX, with a sleek background and stylish text."

#### üîπ Image Generation
The `StableDiffusionPipeline` generated posters based only on the text prompt ‚Äî no brand image/logo integration.

#### üîπ Limitations
- No control over logo or text placement
- No integration of actual uploaded assets
- Text rendering was unreliable in generated images

---

## ‚úÖ Current Updates

### 1. Structured Input Handling
- Accepts **logo**, **background image**, **brand text**, and **image dimensions** as separate inputs
- Inputs are parsed and processed in `main.py` without an external layout engine

### 2. Direct Layout Logic in `main.py`
- A simple **rule-based layout logic** has been implemented in `main.py`
- Calculates bounding boxes for the logo and text manually
- Ensures **non-overlapping**, **visually balanced** placements for initial prototyping

### 3. Integrated Asset Rendering
- Uses `Pillow` and `OpenCV` to process and render:
  - Brand logo onto the background
  - Text in precise layout positions
- Overcomes fidelity issues of native diffusion-based text rendering

### 4. Image Output & Delivery
- Final poster is encoded as a **base64 image**
- Sent back to the frontend and rendered using a standard `<img>` tag

---

## üöÄ Planned Enhancements (Ongoing Research)

The application is evolving into a **Planning + Rendering** framework for structured generative design. Future plans include:
- Integration of layout-aware models like **PlanNet**
- Interpretable and modular layout-to-image pipelines
- Better spatial reasoning and content placement
- Improved layout diversity and branding fidelity

These features are currently in the **prototyping phase.**

---
 
## ‚öôÔ∏è Installation & Setup
### 1. üì¶ Backend (Python + FastAPI)

#### Install dependencies
pip install -r requirements.txt

#### Set Hugging Face Token
You must authenticate with Hugging Face to access CompVis/stable-diffusion-v1-4.
Go to the [`auth_token.py`](./backend/auth_token.py)
- Go the Hugging Face website.
- Create an account.
- Go to Profile Settings
- Click on **Access Tokens**
- Save the Token and copy it
- Paste the auth_token to the auth_token.py file.

#### Run the FastAPI Server
cd backend
uvicorn main:app --reload

### 2. üíª Frontend (Next.js)

#### Navigate to the frontend directory
cd frontend

#### Install Next.js (React + Vite alternative)
npm install

#### Start the server
npm start

Make sure the backend is running on http://localhost:8000 and frontend is configured to point to this backend.

---

## üìö References

- [IJCAI 2022: Layout-Aware Design via Planning](https://www.ijcai.org/proceedings/2022/0692.pdf)
- [Diffusion-Based Document Design (2023)](https://arxiv.org/html/2312.08822v2#S)
- [FastAPI: Request Body Tutorial](https://fastapi.tiangolo.com/tutorial/body/#import-pydantics-basemodel)
- [FastAPI Tutorial (YouTube)](https://www.youtube.com/watch?v=3l16wCsDglU&t=1912s)
- [Stable Diffusion v1.4 on Hugging Face](http://huggingface.co/CompVis/stable-diffusion-v1-4)

---

## Contributor

- **yonishi-13** ‚Äì [GitHub](https://github.com/yonishi-13)

---


